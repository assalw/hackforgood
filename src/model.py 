import sys, os, logging, pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import FeatureUnion
from sklearn.ensemble import AdaBoostClassifier
from sklearn.pipeline import Pipeline
from sklearn.datasets import load_files
from sklearn import metrics
from sklearn.preprocessing import MaxAbsScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score

import numpy as np
import pandas as pd

from flask import Flask

# Flask app
app = Flask(__name__)

# To get stable experimental result
RANDOM_STATE = 66

# Read dataset https://stackoverflow.com/questions/11023411/how-to-import-csv-data-file-into-scikit-learn
input_file = "../dataset/hackforgood_dataset_wadie_model.xlsx"
dataset_df = pd.read_excel(input_file, header = 0)

# Trim whitespaces from column names
dataset_df.rename(columns=lambda x: x.strip(), inplace = True)

# put the original column names in a python list
original_headers = list(dataset_df.columns.values)

# put the numeric column names in a python list
dataframe_numeric = dataset_df._get_numeric_data()
feature_cols = list(dataframe_numeric.columns.values)

# Target column and data
target_cols = ['impact']
target = dataset_df['impact']

# split the dataset in training and test set:
x_train, x_test, y_train, y_test = train_test_split(
    dataframe_numeric, target, test_size=0.20, random_state=RANDOM_STATE)

# Model pipeline
features_pipeline = ('features', FeatureUnion([
        ('vect_w', TfidfVectorizer(min_df=0, max_df=0.98, analyzer="word", ngram_range=(1, 2))),
        ('vect_c', TfidfVectorizer(min_df=0, max_df=0.98, analyzer="char", ngram_range=(1, 2))),
        ('vec', CountVectorizer()),
    ]))

classifier = ("AB", AdaBoostClassifier(n_estimators=250))

scaler = ('min/max scaler', MaxAbsScaler())

model_pipeline = Pipeline([features_pipeline, scaler, classifier])

# Model methods TODO: Wrap in flask
def train():
    model_pipeline.fit(x_train, y_train)

def save_model():
    pickle_out = open("../dataset/hackforgood.model","wb")
    pickle.dump(model_pipeline, pickle_out)
    pickle_out.close()

def validate():
    print("validating with test set")

def predict():
    print("predicted")

# Flask API TODO: Wire to predict function
@app.route('/predict')
def hello_world():
    return 'Hello, World!'

def run_flask_api():
    app.run()

def main():
    train()

if __name__ == "__main__":
    sys.exit(main())